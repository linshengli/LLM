{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNRRV-cigAB"
      },
      "source": [
        "# PyTorch 从零实现知识蒸馏\n",
        "\n",
        "使用 Qwen2.5-0.5B 作为教师模型，从零实现 ~123M 参数的 Decoder-Only Transformer 学生模型，\n",
        "在 Wikipedia 中文子集上进行在线知识蒸馏训练。\n",
        "\n",
        "**运行环境**: Google Colab T4 GPU (15GB VRAM)\n",
        "\n",
        "**模块结构**:\n",
        "- `src/config.py` — 配置数据类\n",
        "- `src/model.py` — 模型架构（RMSNorm, RoPE, GQA, SwiGLU）\n",
        "- `src/data.py` — 数据加载与预处理\n",
        "- `src/trainer.py` — 蒸馏训练循环\n",
        "- `src/generate.py` — 文本生成推理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVg1Qbn5igAC"
      },
      "source": [
        "## Cell 1: 环境检查 & 依赖安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ogR91pXigAC",
        "outputId": "5182d035-9f91-427b-c0cc-72bf907c82f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA 可用: True\n",
            "GPU: Tesla T4\n",
            "显存: 14.7 GB\n",
            "\n",
            "使用设备: cuda\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖（Colab 环境）\n",
        "# !pip install torch transformers datasets matplotlib\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n使用设备: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCg68wOzigAD"
      },
      "source": [
        "## Cell 2: 挂载 Google Drive（可选）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Aqq4fJkigAD",
        "outputId": "7a55b1ef-44ff-4ecc-f759-a631f834316c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "检查点目录: checkpoints/\n"
          ]
        }
      ],
      "source": [
        "# 挂载 Google Drive 用于持久化检查点（可选）\n",
        "# 如果在本地运行，可跳过此 Cell\n",
        "\n",
        "USE_DRIVE = False  # 设置为 True 启用 Google Drive\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    CHECKPOINT_DIR = '/content/drive/MyDrive/distillation_checkpoints/'\n",
        "else:\n",
        "    CHECKPOINT_DIR = 'checkpoints/'\n",
        "\n",
        "import os\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "print(f\"检查点目录: {CHECKPOINT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTC2wt4jigAD"
      },
      "source": [
        "## Cell 3: 导入模块 & 配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J9uP2CxtigAD",
        "outputId": "ec162e45-3186-4c1b-a5a5-84afbc4c8368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 153 (delta 39), reused 145 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (153/153), 644.44 KiB | 2.86 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/LLM\n",
            "Branch 'stage1' set up to track remote branch 'stage1' from 'origin'.\n",
            "Switched to a new branch 'stage1'\n",
            "\u001b[33mcommit 781e195fa91097be8e964c6aa51e13da5dfd103a\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mstage1\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/stage1\u001b[m\u001b[33m)\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 16:19:10 2026 +0800\n",
            "\n",
            "    oom\n",
            "\n",
            "\u001b[33mcommit f296c217ddff59867bf241e64b8399ffc5cfaa5c\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 15:19:59 2026 +0800\n",
            "\n",
            "    for distillation\n",
            "\n",
            "\u001b[33mcommit 274cc8718981d1651ca6f0c4010f60d2fe516035\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/HEAD\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 01:59:50 2026 +0800\n",
            "\n",
            "    add data\n",
            "\n",
            "\u001b[33mcommit 74b4c08825457179a5005dc78997149d626bc196\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 01:28:21 2026 +0800\n",
            "\n",
            "    add colab\n",
            "\n",
            "\u001b[33mcommit 46d756931cda5f5a316655e879f9d1aee7eb1d2f\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 00:54:28 2026 +0800\n",
            "\n",
            "    for colab\n",
            "\n",
            "\u001b[33mcommit ea76b04752f669493bb9cc76188ddada806a4d83\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Tue Feb 10 00:42:53 2026 +0800\n",
            "\n",
            "    for colab\n",
            "\n",
            "\u001b[33mcommit 165c7fcc88d554e0d15c6bd1b64bcc2d1b4793df\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Mon Feb 9 23:27:58 2026 +0800\n",
            "\n",
            "    model for test\n",
            "\n",
            "\u001b[33mcommit 9b038f993591fee934a8f9f38da214d49fe146e5\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Mon Feb 9 23:27:22 2026 +0800\n",
            "\n",
            "    init commit with docs\n",
            "\n",
            "\u001b[33mcommit 8c8d6d7ce02cfa54af3e309ed89c48b48d217cca\u001b[m\n",
            "Author: mark <mark@gmail.com>\n",
            "Date:   Mon Feb 9 15:42:01 2026 +0800\n",
            "\n",
            "    Initial commit from Specify template\n",
            "模型配置: ModelConfig(hidden_size=512, num_layers=12, num_heads=8, num_kv_heads=2, intermediate_size=2048, vocab_size=151665, max_seq_len=512, rope_theta=1000000.0, norm_eps=1e-06, dropout=0.0)\n",
            "预期参数量: ~123,278,336\n",
            "\n",
            "训练配置: TrainingConfig(batch_size=8, learning_rate=0.0003, weight_decay=0.01, warmup_steps=500, num_epochs=3, gradient_clip=1.0, alpha=0.5, temperature=2.0, checkpoint_dir='checkpoints/', log_interval=50, eval_interval=500, save_interval=1000, use_chunked_kl=True, kl_chunk_size=4096)\n"
          ]
        }
      ],
      "source": [
        "# 如果在 Colab 中，需要先克隆项目或上传 src/ 目录\n",
        "# !git clone <repo-url> && cd LLM\n",
        "\n",
        "import sys\n",
        "import os\n",
        "!rm -rf LLM\n",
        "!git clone https://github.com/linshengli/LLM.git\n",
        "%cd /content/LLM\n",
        "!git checkout stage1\n",
        "!git log\n",
        "os.listdir('.')\n",
        "sys.path.insert(0, os.getcwd())  # 确保可以导入 src 模块\n",
        "\n",
        "from src.config import ModelConfig, TrainingConfig\n",
        "from src.model import StudentModel\n",
        "from src.data import load_tokenizer, create_dataloaders\n",
        "from src.trainer import DistillationTrainer, load_teacher_model\n",
        "from src.generate import TextGenerator, load_trained_model\n",
        "\n",
        "# 模型配置\n",
        "model_config = ModelConfig()\n",
        "print(f\"模型配置: {model_config}\")\n",
        "print(f\"预期参数量: ~{151665 * 512 + 3802112 * 12 + 512:,}\")\n",
        "\n",
        "# 训练配置\n",
        "training_config = TrainingConfig(checkpoint_dir=CHECKPOINT_DIR)\n",
        "print(f\"\\n训练配置: {training_config}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0nYGvLIigAD"
      },
      "source": [
        "## Cell 4: 加载 Tokenizer & 构建数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5lvFFQxBigAD",
        "outputId": "75dc0aa3-2e9d-4908-d406-6db94d3cef23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab_size: 151643\n",
            "pad_token: <|endoftext|>\n",
            "\n",
            "训练集 batch 数: 3305\n",
            "验证集 batch 数: 351\n",
            "\n",
            "样本 batch:\n",
            "  input_ids shape: torch.Size([8, 512])\n",
            "  labels shape: torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "# 加载 Tokenizer\n",
        "tokenizer = load_tokenizer()\n",
        "print(f\"Tokenizer vocab_size: {tokenizer.vocab_size}\")\n",
        "print(f\"pad_token: {tokenizer.pad_token}\")\n",
        "\n",
        "# 构建 DataLoader（取 5000 条文章，约 50MB 文本）\n",
        "train_loader, val_loader = create_dataloaders(\n",
        "    tokenizer=tokenizer,\n",
        "    config=training_config,\n",
        "    model_config=model_config,\n",
        "    max_samples=5000,\n",
        ")\n",
        "\n",
        "print(f\"\\n训练集 batch 数: {len(train_loader)}\")\n",
        "print(f\"验证集 batch 数: {len(val_loader)}\")\n",
        "\n",
        "# 验证一个 batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\n样本 batch:\")\n",
        "print(f\"  input_ids shape: {sample_batch['input_ids'].shape}\")\n",
        "print(f\"  labels shape: {sample_batch['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iS-mCaBigAD"
      },
      "source": [
        "## Cell 5: 构建学生模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MQJUs_MxigAD",
        "outputId": "38349335-47d7-4443-f712-e9dbe085a6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学生模型参数量: 123,278,336 (123.3M)\n",
            "\n",
            "模型结构:\n",
            "StudentModel(\n",
            "  (embedding): Embedding(151665, 512)\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x TransformerBlock(\n",
            "      (attention_norm): RMSNorm()\n",
            "      (attention): GQAAttention(\n",
            "        (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (k_proj): Linear(in_features=512, out_features=128, bias=False)\n",
            "        (v_proj): Linear(in_features=512, out_features=128, bias=False)\n",
            "        (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (rotary_emb): RotaryEmbedding()\n",
            "      )\n",
            "      (ffn_norm): RMSNorm()\n",
            "      (ffn): SwiGLUFFN(\n",
            "        (gate_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
            "        (up_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
            "        (down_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): RMSNorm()\n",
            "  (lm_head): Linear(in_features=512, out_features=151665, bias=False)\n",
            ")\n",
            "\n",
            "前向传播验证:\n",
            "  输入: torch.Size([2, 32])\n",
            "  输出: torch.Size([2, 32, 151665])\n",
            "  ✓ 输出形状正确\n",
            "\n",
            "显存占用:\n",
            "  已分配: 0.46 GB\n",
            "  已缓存: 0.48 GB\n"
          ]
        }
      ],
      "source": [
        "# 构建学生模型\n",
        "student_model = StudentModel(model_config)\n",
        "param_count = student_model.count_parameters()\n",
        "print(f\"学生模型参数量: {param_count:,} ({param_count / 1e6:.1f}M)\")\n",
        "print(f\"\\n模型结构:\")\n",
        "print(student_model)\n",
        "\n",
        "# 验证前向传播\n",
        "with torch.no_grad():\n",
        "    test_input = torch.randint(0, model_config.vocab_size, (2, 32))\n",
        "    test_output = student_model(test_input)\n",
        "    print(f\"\\n前向传播验证:\")\n",
        "    print(f\"  输入: {test_input.shape}\")\n",
        "    print(f\"  输出: {test_output.shape}\")\n",
        "    assert test_output.shape == (2, 32, model_config.vocab_size)\n",
        "    print(\"  ✓ 输出形状正确\")\n",
        "\n",
        "# 显存状态\n",
        "if torch.cuda.is_available():\n",
        "    student_model = student_model.to(DEVICE)\n",
        "    print(f\"\\n显存占用:\")\n",
        "    print(f\"  已分配: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"  已缓存: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6Y7xHSkigAD"
      },
      "source": [
        "## Cell 6: 加载教师模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-fXtoW7oigAD",
        "outputId": "87f57e22-b3bb-4627-dad7-cc1113bffb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "ff42b843cd2a49d3aa7b9d96d956ab20",
            "8a5c2576740c4fa697aeaeb6a4034b65",
            "2c0d7bc8cdd743dab6d7cbd5ad8e61d8",
            "13fb46526a1547a79df896eca91b6ae9",
            "7c89be3e739141ac91ebafd5b32473ce",
            "213c0653b199435eb7e107416cc507ce",
            "85459003fec04dac864744b0fe766ea6",
            "b730dc13899b40959a6d985d48bdc52b",
            "3829c6b6c6b643a084279c74451b477b",
            "0acfa21f6d124823a5456145fc724b4a",
            "c07ae8adf8624b96af96d52637f5e029"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff42b843cd2a49d3aa7b9d96d956ab20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "教师模型参数量: 494,032,768 (494.0M)\n",
            "\n",
            "显存占用（学生 + 教师）:\n",
            "  已分配: 1.39 GB\n",
            "  已缓存: 1.45 GB\n",
            "  剩余显存: 13.35 GB\n"
          ]
        }
      ],
      "source": [
        "# 加载教师模型（Qwen2.5-0.5B, FP16）\n",
        "teacher_model = load_teacher_model(device=DEVICE)\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"教师模型参数量: {teacher_params:,} ({teacher_params / 1e6:.1f}M)\")\n",
        "\n",
        "# 显存状态\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\n显存占用（学生 + 教师）:\")\n",
        "    print(f\"  已分配: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"  已缓存: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "    free_mem = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
        "    print(f\"  剩余显存: {free_mem / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxKT2r_yigAD"
      },
      "source": [
        "## Cell 7: 执行蒸馏训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GpYIO1enigAE",
        "outputId": "7ccae43c-e6b9-47ac-aaed-98707ea8da65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "开始蒸馏训练...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "student_logits shape (8, 512, 151665) != teacher_logits shape (8, 512, 151936)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-657020378.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 执行训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"开始蒸馏训练...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n训练完成！共 {len(history['train_loss'])} 步\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LLM/src/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;31m# 计算蒸馏损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 loss, metrics = distillation_loss(\n\u001b[0m\u001b[1;32m    297\u001b[0m                     \u001b[0mstudent_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mteacher_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LLM/src/trainer.py\u001b[0m in \u001b[0;36mdistillation_loss\u001b[0;34m(student_logits, teacher_logits, labels, alpha, temperature, use_chunked_kl, kl_chunk_size)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# 默认走分块版本，避免 log_softmax/softmax 产生 (B,S,V) 的大临时张量导致 OOM。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_chunked_kl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         kl_loss = _kl_div_teacher_student_chunked(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mstudent_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudent_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mteacher_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LLM/src/trainer.py\u001b[0m in \u001b[0;36m_kl_div_teacher_student_chunked\u001b[0;34m(student_logits, teacher_logits, temperature, labels, ignore_index, chunk_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstudent_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mteacher_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;34mf\"student_logits shape {tuple(student_logits.shape)} != \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34mf\"teacher_logits shape {tuple(teacher_logits.shape)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: student_logits shape (8, 512, 151665) != teacher_logits shape (8, 512, 151936)"
          ]
        }
      ],
      "source": [
        "# 创建蒸馏训练器\n",
        "trainer = DistillationTrainer(\n",
        "    student_model=student_model,\n",
        "    teacher_model=teacher_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    config=training_config,\n",
        "    device=DEVICE,\n",
        ")\n",
        "\n",
        "# 执行训练\n",
        "print(\"开始蒸馏训练...\")\n",
        "history = trainer.train()\n",
        "print(f\"\\n训练完成！共 {len(history['train_loss'])} 步\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-57Bwm01igAE"
      },
      "source": [
        "## Cell 8: 绘制 Loss 曲线"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgw5_kNWigAE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 训练 Loss 曲线（使用滑动平均平滑）\n",
        "train_loss = history[\"train_loss\"]\n",
        "window = min(50, len(train_loss) // 5 + 1)\n",
        "if len(train_loss) > window:\n",
        "    smoothed = [sum(train_loss[max(0,i-window):i+1]) / len(train_loss[max(0,i-window):i+1])\n",
        "                for i in range(len(train_loss))]\n",
        "else:\n",
        "    smoothed = train_loss\n",
        "\n",
        "axes[0].plot(train_loss, alpha=0.3, label=\"原始\")\n",
        "axes[0].plot(smoothed, label=f\"滑动平均 (window={window})\")\n",
        "axes[0].set_xlabel(\"训练步数\")\n",
        "axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].set_title(\"训练 Loss 曲线\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 验证 Loss & PPL\n",
        "if history[\"val_loss\"]:\n",
        "    ax2 = axes[1]\n",
        "    ax2.plot(history[\"val_loss\"], \"o-\", color=\"orange\", label=\"验证 Loss\")\n",
        "    ax2.set_xlabel(\"评估次数\")\n",
        "    ax2.set_ylabel(\"Loss\")\n",
        "    ax2.set_title(\"验证集指标\")\n",
        "    ax2_twin = ax2.twinx()\n",
        "    ax2_twin.plot(history[\"val_ppl\"], \"s--\", color=\"green\", label=\"PPL\")\n",
        "    ax2_twin.set_ylabel(\"Perplexity\")\n",
        "    ax2.legend(loc=\"upper left\")\n",
        "    ax2_twin.legend(loc=\"upper right\")\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"training_curves.png\", dpi=150)\n",
        "plt.show()\n",
        "print(\"训练曲线已保存至 training_curves.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_w0fHxfigAE"
      },
      "source": [
        "## Cell 9: 文本生成演示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P4kXBgCigAE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 加载最佳模型\n",
        "best_ckpt = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
        "if not os.path.exists(best_ckpt):\n",
        "    best_ckpt = os.path.join(CHECKPOINT_DIR, \"final.pt\")\n",
        "\n",
        "gen_model = load_trained_model(best_ckpt, model_config, DEVICE)\n",
        "generator = TextGenerator(model=gen_model, tokenizer=tokenizer, device=DEVICE)\n",
        "\n",
        "# 测试提示词\n",
        "prompts = [\n",
        "    \"中国的首都是\",\n",
        "    \"人工智能的发展\",\n",
        "    \"数学是研究\",\n",
        "]\n",
        "\n",
        "strategies = [\"greedy\", \"top_k\", \"top_p\"]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"提示词: {prompt}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for strategy in strategies:\n",
        "        result = generator.generate(\n",
        "            prompt,\n",
        "            max_new_tokens=100,\n",
        "            strategy=strategy,\n",
        "            temperature=0.8,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "        print(f\"\\n[{strategy}]:\")\n",
        "        print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni7id4EiigAE"
      },
      "source": [
        "## Cell 10: 保存最终模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mbOFFxFigAE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 保存最终模型和配置\n",
        "final_save_dir = os.path.join(CHECKPOINT_DIR, \"final_model\")\n",
        "os.makedirs(final_save_dir, exist_ok=True)\n",
        "\n",
        "# 保存模型权重\n",
        "torch.save(\n",
        "    {\n",
        "        \"model_state_dict\": gen_model.state_dict(),\n",
        "        \"model_config\": model_config,\n",
        "        \"training_config\": training_config,\n",
        "    },\n",
        "    os.path.join(final_save_dir, \"model.pt\"),\n",
        ")\n",
        "\n",
        "print(f\"模型已保存至: {final_save_dir}\")\n",
        "model_size = os.path.getsize(os.path.join(final_save_dir, \"model.pt\")) / 1024**2\n",
        "print(f\"模型文件大小: {model_size:.1f} MB\")\n",
        "print(f\"\\n训练摘要:\")\n",
        "print(f\"  学生模型参数量: {param_count:,}\")\n",
        "print(f\"  训练步数: {len(history['train_loss'])}\")\n",
        "if history['val_loss']:\n",
        "    print(f\"  最佳验证 Loss: {min(history['val_loss']):.4f}\")\n",
        "    print(f\"  最佳验证 PPL: {min(history['val_ppl']):.2f}\")\n",
        "print(\"\\n蒸馏训练完成！\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-e5-M6Vi6Ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff42b843cd2a49d3aa7b9d96d956ab20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a5c2576740c4fa697aeaeb6a4034b65",
              "IPY_MODEL_2c0d7bc8cdd743dab6d7cbd5ad8e61d8",
              "IPY_MODEL_13fb46526a1547a79df896eca91b6ae9"
            ],
            "layout": "IPY_MODEL_7c89be3e739141ac91ebafd5b32473ce"
          }
        },
        "8a5c2576740c4fa697aeaeb6a4034b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213c0653b199435eb7e107416cc507ce",
            "placeholder": "​",
            "style": "IPY_MODEL_85459003fec04dac864744b0fe766ea6",
            "value": "Loading weights: 100%"
          }
        },
        "2c0d7bc8cdd743dab6d7cbd5ad8e61d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b730dc13899b40959a6d985d48bdc52b",
            "max": 290,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3829c6b6c6b643a084279c74451b477b",
            "value": 290
          }
        },
        "13fb46526a1547a79df896eca91b6ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0acfa21f6d124823a5456145fc724b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_c07ae8adf8624b96af96d52637f5e029",
            "value": " 290/290 [00:01&lt;00:00, 217.39it/s, Materializing param=model.norm.weight]"
          }
        },
        "7c89be3e739141ac91ebafd5b32473ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213c0653b199435eb7e107416cc507ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85459003fec04dac864744b0fe766ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b730dc13899b40959a6d985d48bdc52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3829c6b6c6b643a084279c74451b477b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0acfa21f6d124823a5456145fc724b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07ae8adf8624b96af96d52637f5e029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}