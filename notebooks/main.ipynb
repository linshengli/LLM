{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 从零实现知识蒸馏\n",
    "\n",
    "使用 Qwen2.5-0.5B 作为教师模型，从零实现 ~123M 参数的 Decoder-Only Transformer 学生模型，\n",
    "在 Wikipedia 中文子集上进行在线知识蒸馏训练。\n",
    "\n",
    "**运行环境**: Google Colab T4 GPU (15GB VRAM)\n",
    "\n",
    "**模块结构**:\n",
    "- `src/config.py` — 配置数据类\n",
    "- `src/model.py` — 模型架构（RMSNorm, RoPE, GQA, SwiGLU）\n",
    "- `src/data.py` — 数据加载与预处理\n",
    "- `src/trainer.py` — 蒸馏训练循环\n",
    "- `src/generate.py` — 文本生成推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: 环境检查 & 依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（Colab 环境）\n",
    "# !pip install torch transformers datasets matplotlib\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"显存: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n使用设备: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: 挂载 Google Drive（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挂载 Google Drive 用于持久化检查点（可选）\n",
    "# 如果在本地运行，可跳过此 Cell\n",
    "\n",
    "USE_DRIVE = False  # 设置为 True 启用 Google Drive\n",
    "\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    CHECKPOINT_DIR = '/content/drive/MyDrive/distillation_checkpoints/'\n",
    "else:\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "\n",
    "import os\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"检查点目录: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: 导入模块 & 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果在 Colab 中，需要先克隆项目或上传 src/ 目录\n",
    "# !git clone <repo-url> && cd LLM\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # 确保可以导入 src 模块\n",
    "\n",
    "from src.config import ModelConfig, TrainingConfig\n",
    "from src.model import StudentModel\n",
    "from src.data import load_tokenizer, create_dataloaders\n",
    "from src.trainer import DistillationTrainer, load_teacher_model\n",
    "from src.generate import TextGenerator, load_trained_model\n",
    "\n",
    "# 模型配置\n",
    "model_config = ModelConfig()\n",
    "print(f\"模型配置: {model_config}\")\n",
    "print(f\"预期参数量: ~{151665 * 512 + 3802112 * 12 + 512:,}\")\n",
    "\n",
    "# 训练配置\n",
    "training_config = TrainingConfig(checkpoint_dir=CHECKPOINT_DIR)\n",
    "print(f\"\\n训练配置: {training_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: 加载 Tokenizer & 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 Tokenizer\n",
    "tokenizer = load_tokenizer()\n",
    "print(f\"Tokenizer vocab_size: {tokenizer.vocab_size}\")\n",
    "print(f\"pad_token: {tokenizer.pad_token}\")\n",
    "\n",
    "# 构建 DataLoader（取 5000 条文章，约 50MB 文本）\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    tokenizer=tokenizer,\n",
    "    config=training_config,\n",
    "    model_config=model_config,\n",
    "    max_samples=5000,\n",
    ")\n",
    "\n",
    "print(f\"\\n训练集 batch 数: {len(train_loader)}\")\n",
    "print(f\"验证集 batch 数: {len(val_loader)}\")\n",
    "\n",
    "# 验证一个 batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\n样本 batch:\")\n",
    "print(f\"  input_ids shape: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"  labels shape: {sample_batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: 构建学生模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建学生模型\n",
    "student_model = StudentModel(model_config)\n",
    "param_count = student_model.count_parameters()\n",
    "print(f\"学生模型参数量: {param_count:,} ({param_count / 1e6:.1f}M)\")\n",
    "print(f\"\\n模型结构:\")\n",
    "print(student_model)\n",
    "\n",
    "# 验证前向传播\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randint(0, model_config.vocab_size, (2, 32))\n",
    "    test_output = student_model(test_input)\n",
    "    print(f\"\\n前向传播验证:\")\n",
    "    print(f\"  输入: {test_input.shape}\")\n",
    "    print(f\"  输出: {test_output.shape}\")\n",
    "    assert test_output.shape == (2, 32, model_config.vocab_size)\n",
    "    print(\"  ✓ 输出形状正确\")\n",
    "\n",
    "# 显存状态\n",
    "if torch.cuda.is_available():\n",
    "    student_model = student_model.to(DEVICE)\n",
    "    print(f\"\\n显存占用:\")\n",
    "    print(f\"  已分配: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"  已缓存: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: 加载教师模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载教师模型（Qwen2.5-0.5B, FP16）\n",
    "teacher_model = load_teacher_model(device=DEVICE)\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "print(f\"教师模型参数量: {teacher_params:,} ({teacher_params / 1e6:.1f}M)\")\n",
    "\n",
    "# 显存状态\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n显存占用（学生 + 教师）:\")\n",
    "    print(f\"  已分配: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"  已缓存: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    free_mem = torch.cuda.get_device_properties(0).total_mem - torch.cuda.memory_allocated()\n",
    "    print(f\"  剩余显存: {free_mem / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: 执行蒸馏训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建蒸馏训练器\n",
    "trainer = DistillationTrainer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=training_config,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# 执行训练\n",
    "print(\"开始蒸馏训练...\")\n",
    "history = trainer.train()\n",
    "print(f\"\\n训练完成！共 {len(history['train_loss'])} 步\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: 绘制 Loss 曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 训练 Loss 曲线（使用滑动平均平滑）\n",
    "train_loss = history[\"train_loss\"]\n",
    "window = min(50, len(train_loss) // 5 + 1)\n",
    "if len(train_loss) > window:\n",
    "    smoothed = [sum(train_loss[max(0,i-window):i+1]) / len(train_loss[max(0,i-window):i+1])\n",
    "                for i in range(len(train_loss))]\n",
    "else:\n",
    "    smoothed = train_loss\n",
    "\n",
    "axes[0].plot(train_loss, alpha=0.3, label=\"原始\")\n",
    "axes[0].plot(smoothed, label=f\"滑动平均 (window={window})\")\n",
    "axes[0].set_xlabel(\"训练步数\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"训练 Loss 曲线\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 验证 Loss & PPL\n",
    "if history[\"val_loss\"]:\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(history[\"val_loss\"], \"o-\", color=\"orange\", label=\"验证 Loss\")\n",
    "    ax2.set_xlabel(\"评估次数\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_title(\"验证集指标\")\n",
    "    ax2_twin = ax2.twinx()\n",
    "    ax2_twin.plot(history[\"val_ppl\"], \"s--\", color=\"green\", label=\"PPL\")\n",
    "    ax2_twin.set_ylabel(\"Perplexity\")\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "    ax2_twin.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_curves.png\", dpi=150)\n",
    "plt.show()\n",
    "print(\"训练曲线已保存至 training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: 文本生成演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 加载最佳模型\n",
    "best_ckpt = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "if not os.path.exists(best_ckpt):\n",
    "    best_ckpt = os.path.join(CHECKPOINT_DIR, \"final.pt\")\n",
    "\n",
    "gen_model = load_trained_model(best_ckpt, model_config, DEVICE)\n",
    "generator = TextGenerator(model=gen_model, tokenizer=tokenizer, device=DEVICE)\n",
    "\n",
    "# 测试提示词\n",
    "prompts = [\n",
    "    \"中国的首都是\",\n",
    "    \"人工智能的发展\",\n",
    "    \"数学是研究\",\n",
    "]\n",
    "\n",
    "strategies = [\"greedy\", \"top_k\", \"top_p\"]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"提示词: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for strategy in strategies:\n",
    "        result = generator.generate(\n",
    "            prompt,\n",
    "            max_new_tokens=100,\n",
    "            strategy=strategy,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        print(f\"\\n[{strategy}]:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: 保存最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 保存最终模型和配置\n",
    "final_save_dir = os.path.join(CHECKPOINT_DIR, \"final_model\")\n",
    "os.makedirs(final_save_dir, exist_ok=True)\n",
    "\n",
    "# 保存模型权重\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": gen_model.state_dict(),\n",
    "        \"model_config\": model_config,\n",
    "        \"training_config\": training_config,\n",
    "    },\n",
    "    os.path.join(final_save_dir, \"model.pt\"),\n",
    ")\n",
    "\n",
    "print(f\"模型已保存至: {final_save_dir}\")\n",
    "model_size = os.path.getsize(os.path.join(final_save_dir, \"model.pt\")) / 1024**2\n",
    "print(f\"模型文件大小: {model_size:.1f} MB\")\n",
    "print(f\"\\n训练摘要:\")\n",
    "print(f\"  学生模型参数量: {param_count:,}\")\n",
    "print(f\"  训练步数: {len(history['train_loss'])}\")\n",
    "if history['val_loss']:\n",
    "    print(f\"  最佳验证 Loss: {min(history['val_loss']):.4f}\")\n",
    "    print(f\"  最佳验证 PPL: {min(history['val_ppl']):.2f}\")\n",
    "print(\"\\n蒸馏训练完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
